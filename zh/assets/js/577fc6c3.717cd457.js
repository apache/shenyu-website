"use strict";(globalThis.webpackChunkshenyu_website=globalThis.webpackChunkshenyu_website||[]).push([[2641],{28453(e,i,n){n.d(i,{R:()=>o,x:()=>a});var t=n(96540);const s={},r=t.createContext(s);function o(e){const i=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:i},e.children)}},61461(e,i,n){n.d(i,{A:()=>t});const t=n.p+"assets/images/ai-token-limiter-api-after-7fc54594554eb138101ed65ab48c8ce5.png"},78690(e,i,n){n.d(i,{A:()=>t});const t=n.p+"assets/images/ai-token-limiter-api-before-cc7312a27b9b44ef36834bc9c28127d3.png"},82442(e,i,n){n.d(i,{A:()=>t});const t=n.p+"assets/images/ai-token-limiter-selector-zh-050f076c8987cb9c9c834684cc01aa17.png"},91162(e,i,n){n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"plugin-center/ai/ai-token-limiter","title":"AiTokenLimiter Plugin","description":"AiTokenLimiter Plugin","source":"@site/versioned_docs/version-2.7.0.1/plugin-center/ai/ai-token-limiter.md","sourceDirName":"plugin-center/ai","slug":"/plugin-center/ai/ai-token-limiter","permalink":"/zh/docs/2.7.0.1/plugin-center/ai/ai-token-limiter","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/shenyu-website/edit/main/versioned_docs/version-2.7.0.1/plugin-center/ai/ai-token-limiter.md","tags":[],"version":"2.7.0.1","frontMatter":{"title":"AiTokenLimiter Plugin","keywords":["AiTokenLimiter"],"description":"AiTokenLimiter Plugin"},"sidebar":"tutorialSidebar","previous":{"title":"AiProxy Plugin","permalink":"/zh/docs/2.7.0.1/plugin-center/ai/ai-proxy"},"next":{"title":"\u81ea\u5b9a\u4e49\u8d1f\u8f7d\u5747\u8861\u7b56\u7565","permalink":"/zh/docs/2.7.0.1/developer/spi/custom-load-balance"}}');var s=n(74848),r=n(28453);const o={title:"AiTokenLimiter Plugin",keywords:["AiTokenLimiter"],description:"AiTokenLimiter Plugin"},a=void 0,l={},c=[{value:"Overview",id:"overview",level:2},{value:"Plugin Configuration",id:"plugin-configuration",level:2},{value:"API Usage",id:"api-usage",level:2}];function d(e){const i={a:"a",blockquote:"blockquote",code:"code",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(i.p,{children:["The ",(0,s.jsx)(i.strong,{children:"aiTokenLimiter"})," plugin is used to track token consumption from LLM responses and enforce rate limiting via Redis. After each response, aiTokenLimiter calculates the number of tokens used and accumulates counts by user or business dimension. If the preset threshold is exceeded, subsequent requests can be rejected or throttled. Note that ShenYu\u2019s rate limiting is typically implemented using Redis to store token buckets or sliding-window states; aiTokenLimiter likewise relies on Redis to record and check token usage. It is most commonly paired with ",(0,s.jsx)(i.strong,{children:"aiProxy"})," for token-based rate limiting."]}),"\n",(0,s.jsx)(i.h2,{id:"plugin-configuration",children:"Plugin Configuration"}),"\n",(0,s.jsxs)(i.p,{children:["When configuring the plugin in the ShenYu admin console, you first create a ",(0,s.jsx)(i.strong,{children:"Selector"}),", then a ",(0,s.jsx)(i.strong,{children:"Rule"}),". A ",(0,s.jsx)(i.strong,{children:"Selector"})," matches request conditions (e.g., path, headers), while a ",(0,s.jsx)(i.strong,{children:"Rule"})," defines plugin parameters or forwarding targets. For more details, see ",(0,s.jsx)(i.a,{href:"../../user-guide/admin-usage/selector-and-rule",children:"Selector and Rule Management"}),"."]}),"\n",(0,s.jsxs)(i.p,{children:["Key fields for ",(0,s.jsx)(i.strong,{children:"aiTokenLimiter"}),":"]}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Selector"}),": Defines which requests to match. For example, set ",(0,s.jsx)(i.code,{children:"Pattern"})," to ",(0,s.jsx)(i.code,{children:"/**"})," to match all requests, or specify a particular route."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Rule"}),": Configure plugin parameters:","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"timeWindowSeconds"}),": Length of the rate-limiting window (in seconds). Within this window, the plugin tallies total token usage and compares it against ",(0,s.jsx)(i.code,{children:"tokenLimit"}),"."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"keyName"}),": Field name in the request used as the rate-limiting \u201cdimension key,\u201d in conjunction with ",(0,s.jsx)(i.code,{children:"aiTokenLimitType"})," (e.g., HEADER, PARAMETER, COOKIE)."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.code,{children:"tokenLimit"}),": Maximum number of tokens allowed within the time window. The plugin counts downstream LLM ",(0,s.jsx)(i.strong,{children:"completion tokens"})," (the tokens consumed by generated content). Once this limit is exceeded, further requests receive an HTTP 429 response."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.p,{children:["Example screenshots of ",(0,s.jsx)(i.strong,{children:"aiTokenLimiter"})," setup in the admin interface:"]}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"ai-token-limiter-selector",src:n(82442).A+"",width:"2595",height:"1048"})}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{alt:"ai-token-limiter-rule",src:n(98873).A+"",width:"2583",height:"1126"})}),"\n",(0,s.jsxs)(i.blockquote,{children:["\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.strong,{children:"Note:"})," The ",(0,s.jsx)(i.strong,{children:"aiTokenLimiter"})," plugin depends on ",(0,s.jsx)(i.strong,{children:"aiProxy"}),". In a typical flow, apply ",(0,s.jsx)(i.strong,{children:"AiPrompt"})," (if injecting a prompt), then ",(0,s.jsx)(i.strong,{children:"AiTokenLimiter"})," (for token counting/rate limiting), and finally ",(0,s.jsx)(i.strong,{children:"AiProxy"})," (to forward the request to the LLM). Ensure that ",(0,s.jsx)(i.strong,{children:"AiTokenLimiter"}),"\u2019s ",(0,s.jsx)(i.strong,{children:"sort"})," value is ",(0,s.jsx)(i.strong,{children:"less than"})," ",(0,s.jsx)(i.strong,{children:"AiProxy"})," and ",(0,s.jsx)(i.strong,{children:"greater than"})," ",(0,s.jsx)(i.strong,{children:"AiPrompt"})," in the \u201cPlugin Management\u201d list."]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"api-usage",children:"API Usage"}),"\n",(0,s.jsxs)(i.p,{children:["With ",(0,s.jsx)(i.strong,{children:"AiProxy"})," and ",(0,s.jsx)(i.strong,{children:"AiTokenLimiter"})," enabled, send requests through the ShenYu gateway (e.g., via Postman) to proxy LLM calls:"]}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-bash",children:'curl --location --request POST \'http://localhost:9195/ai/proxy/v1/chat/completions\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'{\n    "model": "gpt-4o-mini",\n    "messages": [\n        {\n            "role": "user",\n            "content": "\u6211\u4e8e\u6740\u622e\u4e4b\u4e2d\u76db\u653e\uff0c\u4ea6\u5982\u9ece\u660e\u4e2d\u7684\u82b1\u6735"\n        }\n    ]\n}\'\n'})}),"\n",(0,s.jsxs)(i.p,{children:["Example request (before rate limiting):\n",(0,s.jsx)(i.img,{alt:"ai-proxy-api",src:n(78690).A+"",width:"892",height:"1079"})]}),"\n",(0,s.jsx)(i.p,{children:"If you set tokenLimit=10 and make another request within 60 seconds, AiTokenLimiter will intercept it, return HTTP 429, and indicate that the token usage limit has been reached. Please try again later."}),"\n",(0,s.jsxs)(i.p,{children:["Example response (after rate limiting):\n",(0,s.jsx)(i.img,{alt:"ai-proxy-api",src:n(61461).A+"",width:"725",height:"596"})]})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},98873(e,i,n){n.d(i,{A:()=>t});const t=n.p+"assets/images/ai-token-limiter-rule-zh-672a88bbeb70045a60ecfcc39d406ea6.png"}}]);